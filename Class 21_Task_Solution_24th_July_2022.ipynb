{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Class 21_Task Solution_24th July 2022.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**TASK SOLUTION: 24th July 2022**\n",
        "\n",
        "We have Attribute Dataset  and Dress Sales Dataset. These are connected to each other based on Dress_ID. Perform the Following Task:\n",
        "\n",
        "\n",
        "1. Create a Table of attribute dataset and dress dataset in mysql workbench/python\n",
        "2. Do a bulk load for these 2 tables for respective dataset in mysql workbench/python\n",
        "3. Read these datasets in pandas as a dataframe\n",
        "4. Convert Attribute Dataset in JSON Format (.to_json will be used)\n",
        "5. Store this json dataset into mongodb (Insert_many will be used)\n",
        "6. In SQL task, try to perform left join operation with Attribute dataset and dress dataset on column Dress_ID\n",
        "7. Write the SQL query to find out how many unique dress that we have based on Dress_ID\n",
        "8. Try to find out how many dress is having recommendation as 0\n",
        "9. Try to find out total dress sales for each and every Dress_ID\n",
        "10. Try to find out the third highest most selling Dress_ID"
      ],
      "metadata": {
        "id": "aV3ozLvGZl7D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtXI0w9wZgg9"
      },
      "outputs": [],
      "source": [
        "#Task 1 and Task 2 Done\n",
        "#MySQL Code\n",
        "show databases;\n",
        "create database task;\n",
        "use task;\n",
        "\n",
        "#Creating table for Attribute Dataset\n",
        "create table if not exists attribute_data_v1 (\n",
        "dress_id int ,\n",
        "style varchar(30) , \n",
        "price varchar(30) , \n",
        "rating decimal (2,1) ,\n",
        "size varchar(30),\n",
        "season varchar(30),\n",
        "neckline varchar(30),\n",
        "sleevelength varchar(30) , \n",
        "waiseline varchar(30) ,\n",
        "material varchar(30) , \n",
        "fabrictype varchar(30) , \n",
        "decoration varchar(30) , \n",
        "patterntype varchar(30) , \n",
        "recommendation int\n",
        ");\n",
        "\n",
        "\n",
        "#Inserting Attribute Dataset Records\n",
        "LOAD DATA INFILE '\\Attribute DataSet.csv' INTO TABLE attribute_data_v1\n",
        "FIELDS TERMINATED BY ','\n",
        "ENCLOSED BY '\"'\n",
        "LINES TERMINATED BY '\\r\\n'\n",
        "IGNORE 1 LINES;\n",
        "\n",
        "#Checking the data\n",
        "select * from attribute_data_v1; #Coming Properly\n",
        "\n",
        "#Creating table for Dress Sales\n",
        "create table if not exists dress_sales_v1 (\n",
        "dress_id int ,\n",
        "`29/8/2013` int , \n",
        "`31/8/2013` int , \n",
        "`2/9/2013` int ,\n",
        "`4/9/2013` int ,\n",
        "`6/9/2013` int,\n",
        "`8/9/2013` int,\n",
        "`10/9/2013` int , \n",
        "`12/9/2013` int ,\n",
        "`14/9/2013` int , \n",
        "`16/9/2013` int , \n",
        "`18/9/2013` int , \n",
        "`20/9/2013` int , \n",
        "`22/9/2013` int ,\n",
        "`24/9/2013` int ,\n",
        "`26/9/2013` int ,\n",
        "`28/9/2013` int ,\n",
        "`30/9/2013` int ,\n",
        "`2/10/2013` int ,\n",
        "`4/10/2013` int ,\n",
        "`6/10/2013` int ,\n",
        "`8/10/2013` int ,\n",
        "`10/10/2013` int ,\n",
        "`12/10/2013` int\n",
        ");\n",
        "\n",
        "#Inserting Attribute Dataset Records\n",
        "LOAD DATA INFILE '\\Dress Sales.csv' INTO TABLE dress_sales_v1\n",
        "FIELDS TERMINATED BY ','\n",
        "ENCLOSED BY '\"'\n",
        "LINES TERMINATED BY '\\r\\n'\n",
        "IGNORE 1 LINES;\n",
        "\n",
        "select * from dress_sales_v1 #Coming Correctly\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 3\n",
        "!pip install mysql-connector-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3igTPtwJZbDs",
        "outputId": "66e4bda4-64b3-4eba-b1b1-f29376e78f85"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mysql-connector-python\n",
            "  Downloading mysql_connector_python-8.0.29-cp37-cp37m-manylinux1_x86_64.whl (25.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.2 MB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from mysql-connector-python) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.0.0->mysql-connector-python) (1.15.0)\n",
            "Installing collected packages: mysql-connector-python\n",
            "Successfully installed mysql-connector-python-8.0.29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 3\n",
        "import mysql.connector as connection\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "mydb = connection.connect(host = \"Localhost\", user = \"root\", passwd = \"gopalkanakESHA@94\", use_pure = True)\n",
        "print(mydb)\n",
        "\n",
        "#Run SQL\n",
        "sql_query1 = pd.read_sql('select * from task.attribute_data_v1', mydb)\n",
        "sql_query2 = pd.read_sql('select * from task.dress_sales_v1', mydb)\n",
        "\n",
        "\n",
        "#Convert SQL to DataFrame\n",
        "attribute_data = pd.DataFrame(sql_query1, columns = ['dress_id', 'style', 'price','rating','size','season','neckline',\n",
        "                                        'sleevelength','waiseline','material','fabrictype','decoration',\n",
        "                                        'patterntype','recommendation'])\n",
        "\n",
        "dress_sales = pd.DataFrame(sql_query2, columns = ['dress_id','29/8/2013', '31/8/2013', '2/9/2013','4/9/2013','6/9/2013','8/9/2013','10/9/2013',\n",
        "                                        '12/9/2013','14/9/2013','16/9/2013','18/9/2013','20/9/2013','22/9/2013','24/9/2013'\n",
        "                                        '24/9/2013','26/9/2013','28/9/2013','30/9/2013','2/10/2013','4/10/2013','6/10/2013',\n",
        "                                        '8/10/2013','10/10/2013','12/10/2013'])\n",
        "\n",
        "\n",
        "print(attribute_data) #Coming Correctly\n",
        "print(dress_sales) #Coming Correctly"
      ],
      "metadata": {
        "id": "0wPFMK7EaN_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 4\n",
        "#Converting Attribute Dataset dataframe into json\n",
        "attribute_data_json = attribute_data.to_json()"
      ],
      "metadata": {
        "id": "y7XQ0P40rsD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 5\n",
        "#Storing JSON into MongoDB\n",
        "import pymongo\n",
        "import json\n",
        "from pymongo import MongoClient, InsertOne\n",
        "client = pymongo.MongoClient(\"mongodb+srv://gauravratan:useyourpwd@cluster0.hunum.mongodb.net/?retryWrites=true&w=majority\") #Connectivity between python and MongoDB\n",
        "db2 = client.test\n",
        "\n",
        "#Creating Database\n",
        "database = client['Task']\n",
        "#Creating Collection/Document inside Database (Same as creating Tables inside Database in SQL Systems)\n",
        "collection = database[\"Json\"]\n",
        "#Replacing single quotes with double quotes on attribute_data_json to make it valid json\n",
        "\n",
        "print(attribute_data_json)\n",
        "\n",
        "#Storing JSON Data into MongoDB\n",
        "#Loading or Opening the json file\n",
        "with open(r'C:\\Users\\kiit\\PycharmProjects\\Class 21_24th July 2022_Task\\attribute_data.json') as file:\n",
        "    file_data = json.load(file)\n",
        "\n",
        "# Inserting the loaded data in the Collection\n",
        "# if JSON contains data more than one entry\n",
        "# insert_many is used else insert_one is used\n",
        "\n",
        "if isinstance(file_data, list):\n",
        "    collection.insert_many(file_data)\n",
        "else:\n",
        "    collection.insert_one(file_data)"
      ],
      "metadata": {
        "id": "oFgWJq3PrwwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 6\n",
        "#Left Join with Attribute Dataset and Dress Sales Dataset\n",
        "\n",
        "joined_data = pd.merge(attribute_data,dress_sales,how = 'left',on = 'dress_id')\n",
        "print(joined_data)\n"
      ],
      "metadata": {
        "id": "VNiYcx7QsIRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 7\n",
        "#Write the SQL query to find out how many unique dress that we have based on Dress_ID\n",
        "import mysql.connector as connection\n",
        "mydb = connection.connect(host = \"Localhost\", user = \"root\", passwd = \"Useyourpwd@94\", use_pure = True)\n",
        "cursor = mydb.cursor()\n",
        "cursor.execute(\"select count(distinct(dress_id)) from task.attribute_data_v1\")\n",
        "for i in cursor.fetchall():\n",
        "  print(i) #Gives answer (475,)"
      ],
      "metadata": {
        "id": "jO3LePiDsvct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 8\n",
        "#Try to find out how many dress is having recommendation as 0\n",
        "print((attribute_data.recommendation == 0).sum())  #290 such values. In SQL we can write: select count(*) from table name where recommendation = 0"
      ],
      "metadata": {
        "id": "ldU1AXznufA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 9\n",
        "#Find the total sales for each and every dress id\n",
        "#Creating Column Total Sales for each Dress ID\n",
        "dress_sales['Sales'] = dress_sales[['29/8/2013', '31/8/2013', '2/9/2013','4/9/2013','6/9/2013','8/9/2013','10/9/2013',\n",
        "                                        '12/9/2013','14/9/2013','16/9/2013','18/9/2013','20/9/2013','22/9/2013','24/9/2013'\n",
        "                                        ,'26/9/2013','28/9/2013','30/9/2013','2/10/2013','4/10/2013','6/10/2013',\n",
        "                                        '8/10/2013','10/10/2013','12/10/2013']].agg('sum', axis=1)\n",
        "\n",
        "#Rolling up at Unique Dress Id Level\n",
        "print(dress_sales.groupby('dress_id')['Sales'].sum()) #This will provide the rolled up sum of sales of each unique dress_id. Similarily we can do in SQL also"
      ],
      "metadata": {
        "id": "5UWrniSCvlbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 10\n",
        "#Try to find out the third highest most selling Dress_ID\n",
        "sales_data = dress_sales.groupby('dress_id')['Sales'].sum().reset_index().rename(columns={'sum':'Sales','dress_id' : 'dress_id'})\n",
        "print(sales_data)\n",
        "print(sales_data.Sales.nlargest(3).iloc[-1]) #Getting 75979 as 3rd largest sum\n",
        "\n",
        "#If we have to do in SQL then query will be\n",
        "SELECT DISTINCT SALES AS 3RDHighestSales\n",
        "FROM DRESS_SALES_TABLE\n",
        "ORDER BY SALES DESC\n",
        "LIMIT 1 \n",
        "OFFSET 2;\n"
      ],
      "metadata": {
        "id": "AwNdEZ5ZzUy1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
